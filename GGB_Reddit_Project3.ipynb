{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Classifying Reddit posts\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Statement\n",
    "Given students' changing attitudes on unethical behaviors, and given corporations' increasingly-rigorous job applicant screening processes, are models based on natural language processing sophisticated enough to distinguish the linguistic nuances between ethical, unethical, and illegal behaviors posted online?  Could these models be the basis for more sophiticated job screeing tools in the future, and therefore put already ethically at-risk students at even more more of a disadvantage for employment. What are the implications and actions for educators?\n",
    "\n",
    "---\n",
    "\n",
    "## Executive summary\n",
    "A recent study by professors at California State University, San Marcos and San Francisco State University, found that students' who were more open to cheating at school also were more open to unethical behavior later on in their jobs and careers. In addition, the study found that 'group-oriented' students had a more relaxed attitude toward cheating than more 'individualistic' students. (1)\n",
    "\n",
    "A report by Career Builder.com found that up to 70% of businesses use social media as a screening tool for job applicants and new hires.(2)  Top reasons for job denial include: \n",
    "- Provocative/inappropriate content, photos, videos = 40%\n",
    "- Alcohol and drug use = 36%\n",
    "- Descrimination againse race,gender, religion = 31%\n",
    "- Illegal and criminal behavior = 30%\n",
    "\n",
    "Is machine learning sophisticated enough to distinguish linguistic nuances between ethical, unethical, and illegal behaviors posted online and how does this affect students and educators?\n",
    "\n",
    "A high-level study was conducted on Reddit posts spanning the 'Life Pro Tip' , the 'Unethical Life Pro Tip', and the 'Illegal Life Pro Tip' subreddit groups using the following modelling techniques to determine the predictive capabilities of machine learning. \n",
    "- CountVectorizer / TfidfVectorizer\n",
    "- Logistic Regression\n",
    "- Naïve Bayes: Binomial/ Multinomial\n",
    "- Support Vector\n",
    "- Decision Tree\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Contents\n",
    "1. Gathering data\n",
    "- Cleaning data\n",
    "- Modelling data\n",
    ">- Model 1: Logistic Regression, Naive Bayes\n",
    ">- Model 2: Logistic Regression, Naive Bayes, Support Vector Classification\n",
    ">- Model 3: Logistic Regression, Naive Bayes, Decision Tree\n",
    "\n",
    "---\n",
    "\n",
    "## Results\n",
    "\n",
    "Three sets of data were run:\n",
    "- Data 1 = Predicting Unethical vs Ethical posts\n",
    "- Data 2 = Predicting Illegal vs Unethical posts\n",
    "- Data 3 = Predicting Illegal vs Ethical posts\n",
    "\n",
    "Overall results concerning all 3 data sets:\n",
    "- Titles more accurate than selftext\n",
    "- Tvec more accurate than Cvec\n",
    "- Stopwords not an influence - even when creating custom stopword list\n",
    "- LogReg most accurate model!\n",
    "- Multinomial Naïve Bayes slightly less accuracy than LogReg but consistently higher Specificity\n",
    "- Support Vector similar accuracy to LogReg, but with higher overfit and HUGE Time/CPU cost.\n",
    "- Decision Tree (even with up to 90 levels) ran surprisingly quickly, but had slightly less accuracy than LogReg and had the highest overfit.\n",
    "\n",
    "Results for best fit models:\n",
    "\n",
    "|Dataset|Reddit|Baseline|Best model|Results|\n",
    "|---|---|---|---|---|\n",
    "|Data1|Unethical vs Ethical|54%|Tvec and LogReg| Accuracy 78%|\n",
    "|Data2|Illegal vs Unethical| 52%| Tvec and LogReg|Accuracy 76%|\n",
    "|Data3|Illegal vs Ethical|52%|Tvec and LogReg|Accuracy 90%|\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusions and Recommendations\n",
    "\n",
    "Simple modeling yields reasonable accuracy in predicting if a post and its associated behavior can be categorized as unethical or illegal.  More data sourced, additional feature engineering, and more modelling tecniques will increase accuracy.  It is reasonable to assume employers are capable of screening students and new job candidates based on machine learning nuanced language.\n",
    "\n",
    "Recommendations:\n",
    "- Expand on current study to : 1) ensure modelling accuracy, and 2) refine how online groups influence students’ ‘collectivism’\n",
    "- Advise University Career Services to enact stricter guidance to graduating students about cleaning and maintaining social profiles.\n",
    "- Approach University staff to urge more overall education in Ethics.  Ethics is standard study for many disciplines, medical, legal, business, theology.  Increased education in ethics at an earlier stage can begin to curb unhealthy attitudes toward scholastic cheating.\n",
    "\n",
    "\n",
    "(1)https://www.sciencedaily.com/releases/2019/11/191127121235.htm\n",
    "(2)https://www.cnbc.com/2018/08/10/digital-dirt-may-nix-that-job-you-were-counting-on-getting.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online posts sraped from following subreddits:\n",
    "- LifeProTips='https://www.reddit.com/r/LifeProTips.json'\n",
    "- UnethicalLifeProTips='https://www.reddit.com/r/UnethicalLifeProTips.json'\n",
    "- IllegalLifePro Tips='https://www.reddit.com/r/IllegalLifeProTips.json'\n",
    "\n",
    "|Feature|Type|Subreddit/dataset|Description|\n",
    "|---|---|---|---|\n",
    "|title|string |Regular'Ethical'/Unethical/Illegal Life Pro Tips|Title of the post|\n",
    "|selftext|string|Ethical/Unethical/Illegal|Body of the text|\n",
    "|subreddit|string/int|Ethical/Unethical/Illegal|Identifier for specific subreddit|\n",
    "|author|string|Ethical/Unethical/Illegal|Author of post|\n",
    "|num_comments|int|Ethical/Unethical/Illegal|Number of comments per post|\n",
    "|score|int|Ethical/Unethical/illegal|Score (thumbs up) per post|\n",
    "|is_self|string|Ethical/Unethical/Illegal|Reddit indicatro of type of post|\n",
    "|created_UTC/timestamp|date/time|Ethical/Unethical/Illegal|Timestamps for post|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing tools and data\n",
    "### Import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data from the following websits\n",
    "- my_url='https://www.reddit.com/r/LifeProTips.json'\n",
    "- my_url='https://www.reddit.com/r/UnethicalLifeProTips.json'\n",
    "- my_url='https://www.reddit.com/r/IllegalLifeProTips.json'\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Original request code for data gathering \n",
    "### Code not used, but saved as reference for alternative data gathering method\n",
    "#### Connect to reddit pages and make sure status code is good #### Double click here to see the code\n",
    "\n",
    "my_url='https://www.reddit.com/r/LifeProTips.json'\n",
    "my_url='https://www.reddit.com/r/UnethicalLifeProTips.json'\n",
    "my_url='https://www.reddit.com/r/IllegalLifeProTips.json'\n",
    "\n",
    "my_header={'User-agent':'gg_agent'}\n",
    "res=requests.get(my_url,headers=my_header)\n",
    "my_json=res.json()\n",
    "res.status_code, my_json['data']['after']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull reddit posts and save to a file #### Double click here to see the code\n",
    "\n",
    "post=[]\n",
    "after=None\n",
    "for i in range(300):\n",
    "    if after==None:\n",
    "        params={}\n",
    "    else:params={'after':after}\n",
    "    res=requests.get(my_url,headers=my_header,params=params)\n",
    "    if res.status_code==200:\n",
    "        my_json=res.json()\n",
    "        post.extend(my_json['data']['children'])\n",
    "        after=my_json['data']['after']\n",
    "    else:\n",
    "        print(res.status_code)\n",
    "        break\n",
    "    time.sleep(2)  # this slows the code down to signal reddit you are not hostile\n",
    "    #print(i)\n",
    "    if i>0 and i%5==0:\n",
    "        pd.DataFrame(post).to_csv('ILPT_reddit.csv',index=False)\n",
    "        print(f\"Saved {len(post)} posts\")\n",
    "        \n",
    "\n",
    "\n",
    "df = df.drop_duplicates(subset='data', keep=\"first\")\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "type(eval(df.data.iloc[2]))\n",
    "df['subreddit'], df['title'], df['selftext'], df['num_comments']= ['x', 'y', 'z', 0]\n",
    "\n",
    "#we pull out the dictionary values we want\n",
    "my_colnames= ['subreddit','title', 'selftext','num_comments']\n",
    "for j in my_colnames:\n",
    "    for i in range(0,len(df)):\n",
    "        df[j][i] = eval(df.data.iloc[i])[j]    \n",
    "\n",
    "#I notice some of the messages are reddit notifications and not real posts\n",
    "#this function selects those posts with 'LPT\" in it (ie LPT and ULPT and ILPT) and discards the rest\n",
    "df = df[df['title'].str.contains(\"LPT\")]\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 PushIO code for data gathering\n",
    "#### BIG THANKS TO RAFFY for sharing  #### Double click to see code\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "def get_date(created):\n",
    "    # get the date of post\n",
    "    return dt.date.fromtimestamp(created)\n",
    "\n",
    "def query_pushshift(subreddit, kind='submission', skip=5, times=50, \n",
    "                    subfield = ['title', 'selftext', 'subreddit', 'created_utc', 'author', 'num_comments',\n",
    "                                'score', 'is_self'],\n",
    "                    comfields = ['body', 'score', 'created_utc']):\n",
    "    # get the base url that contains information I want to scrape where 'kind' are all submitted posts\n",
    "    # and 'subreddit' is the specified subreddit. Get 500 posts.\n",
    "    stem = f\"https://api.pushshift.io/reddit/search/{kind}/?subreddit={subreddit}&size=500\"\n",
    "    # instantiate list to contain \n",
    "    mylist = []\n",
    "    # scrape posts from the subreddit 'times' times\n",
    "    for x in range(1, times + 1):\n",
    "        # Get posts 'skip' * 'x' days ago\n",
    "        URL = f\"{stem}&after={skip * x}d\"\n",
    "        print(URL)\n",
    "        # Scrape URL\n",
    "        response = requests.get(URL)\n",
    "        # Give me an AssertionError if status code not 200\n",
    "        assert response.status_code == 200\n",
    "        # Of the HTML scraped, take the values of 'data'\n",
    "        the_json=response.json()\n",
    "        no_blanks=[c for c in the_json['data'] if ('selftext' in c.keys()) and len(c['selftext'])>10]\n",
    "        # turn the data into a dataframe\n",
    "        df = pd.DataFrame.from_dict(no_blanks)\n",
    "        # append the dataframe to mylist\n",
    "        mylist.append(df)\n",
    "        # wait to not overrun Reddit's resources\n",
    "        time.sleep(3)\n",
    "    # concatenate the dataframes together as one large dataframe, full\n",
    "    full = pd.concat(mylist, sort=False)\n",
    "    if kind == \"submission\":\n",
    "        # take all speficied data\n",
    "        full = full[subfield]\n",
    "        # drop duplicate rows\n",
    "        full = full.drop_duplicates()\n",
    "        full = full.loc[full['is_self'] == True]\n",
    "    # date the the post was... posted\n",
    "    _timestamp = full[\"created_utc\"].apply(get_date)\n",
    "    full['timestamp'] = _timestamp\n",
    "    print(full.shape)\n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_uneth = query_pushshift(subreddit = 'unethicallifeprotips', skip = 1, times=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_eth.to_csv(\"eth_reddit.csv\",index=False, header=True)\n",
    "df_uneth.to_csv(\"uneth_reddit.csv\", index=False, header=True)\n",
    "#df_illegal.to_csv(\"illegal_reddit.csv\", index=False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean Data\n",
    "#### Please note, the following code was run several times to create multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ULPT - Got some business cards of people you d...</td>\n",
       "      <td>Keep 'em! If you ever hit a parked car, write ...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580345880</td>\n",
       "      <td>cibtd</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ULPT Request: How to return an unwanted survei...</td>\n",
       "      <td>Won a raffle and the prize was a google smart ...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580346688</td>\n",
       "      <td>2humps1camel</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ULPT Request: I need a free White Pages Premiu...</td>\n",
       "      <td>Anyone know how I might accomplish that?</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580349400</td>\n",
       "      <td>YetAnotherStepBack</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ULPT: Help improve vaccination rates by encour...</td>\n",
       "      <td>Next flu season, vaccination rates will be hig...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580350376</td>\n",
       "      <td>cramduck</td>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ULPT: How to get away with anything using a ca...</td>\n",
       "      <td>Place one or multiple cameras in the area you ...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580350881</td>\n",
       "      <td>becuziwasinverted</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  ULPT - Got some business cards of people you d...   \n",
       "1  ULPT Request: How to return an unwanted survei...   \n",
       "2  ULPT Request: I need a free White Pages Premiu...   \n",
       "3  ULPT: Help improve vaccination rates by encour...   \n",
       "4  ULPT: How to get away with anything using a ca...   \n",
       "\n",
       "                                            selftext             subreddit  \\\n",
       "0  Keep 'em! If you ever hit a parked car, write ...  UnethicalLifeProTips   \n",
       "1  Won a raffle and the prize was a google smart ...  UnethicalLifeProTips   \n",
       "2           Anyone know how I might accomplish that?  UnethicalLifeProTips   \n",
       "3  Next flu season, vaccination rates will be hig...  UnethicalLifeProTips   \n",
       "4  Place one or multiple cameras in the area you ...  UnethicalLifeProTips   \n",
       "\n",
       "   created_utc              author  num_comments  score  is_self   timestamp  \n",
       "0   1580345880               cibtd             4      1     True  2020-01-29  \n",
       "1   1580346688        2humps1camel             6      1     True  2020-01-29  \n",
       "2   1580349400  YetAnotherStepBack             1      1     True  2020-01-29  \n",
       "3   1580350376            cramduck           277      1     True  2020-01-29  \n",
       "4   1580350881   becuziwasinverted             4      1     True  2020-01-29  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('eth_reddit.csv')\n",
    "df = pd.read_csv('uneth_reddit.csv')\n",
    "#df = pd.read_csv('illegal_reddit.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>- Got some business cards of people you don't...</td>\n",
       "      <td>Keep 'em! If you ever hit a parked car, write ...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580345880</td>\n",
       "      <td>cibtd</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Request: How to return an unwanted surveillan...</td>\n",
       "      <td>Won a raffle and the prize was a google smart ...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580346688</td>\n",
       "      <td>2humps1camel</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Request: I need a free White Pages Premium ac...</td>\n",
       "      <td>Anyone know how I might accomplish that?</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580349400</td>\n",
       "      <td>YetAnotherStepBack</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Help improve vaccination rates by encouraging...</td>\n",
       "      <td>Next flu season, vaccination rates will be hig...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580350376</td>\n",
       "      <td>cramduck</td>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>How to get away with anything using a camera!</td>\n",
       "      <td>Place one or multiple cameras in the area you ...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580350881</td>\n",
       "      <td>becuziwasinverted</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   - Got some business cards of people you don't...   \n",
       "1   Request: How to return an unwanted surveillan...   \n",
       "2   Request: I need a free White Pages Premium ac...   \n",
       "3   Help improve vaccination rates by encouraging...   \n",
       "4      How to get away with anything using a camera!   \n",
       "\n",
       "                                            selftext             subreddit  \\\n",
       "0  Keep 'em! If you ever hit a parked car, write ...  UnethicalLifeProTips   \n",
       "1  Won a raffle and the prize was a google smart ...  UnethicalLifeProTips   \n",
       "2           Anyone know how I might accomplish that?  UnethicalLifeProTips   \n",
       "3  Next flu season, vaccination rates will be hig...  UnethicalLifeProTips   \n",
       "4  Place one or multiple cameras in the area you ...  UnethicalLifeProTips   \n",
       "\n",
       "   created_utc              author  num_comments  score  is_self   timestamp  \n",
       "0   1580345880               cibtd             4      1     True  2020-01-29  \n",
       "1   1580346688        2humps1camel             6      1     True  2020-01-29  \n",
       "2   1580349400  YetAnotherStepBack             1      1     True  2020-01-29  \n",
       "3   1580350376            cramduck           277      1     True  2020-01-29  \n",
       "4   1580350881   becuziwasinverted             4      1     True  2020-01-29  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REALLY cool function to aid in editing string!\n",
    "import string\n",
    "\n",
    "# this function removes the LPT or ULPT or ILPT from the start of the title\n",
    "# otherwise it would be too easy to predict the post!\n",
    "df['title'] = df['title'].str.lstrip('ILPT:')\n",
    "df['title'] = df['title'].str.lstrip('ULPT:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>- Got some business cards of people you don't ...</td>\n",
       "      <td>Keep 'em! If you ever hit a parked car, write ...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580345880</td>\n",
       "      <td>cibtd</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>How to return an unwanted surveillance device ...</td>\n",
       "      <td>Won a raffle and the prize was a google smart ...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580346688</td>\n",
       "      <td>2humps1camel</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I need a free White Pages Premium account.</td>\n",
       "      <td>Anyone know how I might accomplish that?</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580349400</td>\n",
       "      <td>YetAnotherStepBack</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Help improve vaccination rates by encouraging ...</td>\n",
       "      <td>Next flu season, vaccination rates will be hig...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580350376</td>\n",
       "      <td>cramduck</td>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>How to get away with anything using a camera!</td>\n",
       "      <td>Place one or multiple cameras in the area you ...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1580350881</td>\n",
       "      <td>becuziwasinverted</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-01-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  - Got some business cards of people you don't ...   \n",
       "1  How to return an unwanted surveillance device ...   \n",
       "2         I need a free White Pages Premium account.   \n",
       "3  Help improve vaccination rates by encouraging ...   \n",
       "4      How to get away with anything using a camera!   \n",
       "\n",
       "                                            selftext             subreddit  \\\n",
       "0  Keep 'em! If you ever hit a parked car, write ...  UnethicalLifeProTips   \n",
       "1  Won a raffle and the prize was a google smart ...  UnethicalLifeProTips   \n",
       "2           Anyone know how I might accomplish that?  UnethicalLifeProTips   \n",
       "3  Next flu season, vaccination rates will be hig...  UnethicalLifeProTips   \n",
       "4  Place one or multiple cameras in the area you ...  UnethicalLifeProTips   \n",
       "\n",
       "   created_utc              author  num_comments  score  is_self   timestamp  \n",
       "0   1580345880               cibtd             4      1     True  2020-01-29  \n",
       "1   1580346688        2humps1camel             6      1     True  2020-01-29  \n",
       "2   1580349400  YetAnotherStepBack             1      1     True  2020-01-29  \n",
       "3   1580350376            cramduck           277      1     True  2020-01-29  \n",
       "4   1580350881   becuziwasinverted             4      1     True  2020-01-29  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this function removes the word 'Request' from the start of the title \n",
    "# I noticed that many of the 'illegal'LPT were requests and this could sway results\n",
    "#DECISION made to remove \"request\" from all posts\n",
    "df['title'] = df['title'].str.lstrip(' Request:')\n",
    "df['title'] = df['title'].str.lstrip(' request:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7154"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6768"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get rid of posts with little/ no text in title\n",
    "df = df.drop(df[df.title.str.len() < 20].index)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6679"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of posts with duplicate titles\n",
    "df = df.drop_duplicates(subset='title', keep=\"first\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6614"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We get rid of posts with little/ no text in selftext\n",
    "df = df.drop(df[df.selftext.str.len() < 20].index)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6501"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of posts with duplicate selftexts\n",
    "df = df.drop_duplicates(subset='selftext', keep=\"first\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6447"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we drop posts where the selftext is just a website\n",
    "df = df.drop(df[df['selftext'].str.match('http')].index)\n",
    "df = df.drop(df[df['selftext'].str.match('\\\\[http')].index)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dirtymoney      19\n",
       "sportscience    15\n",
       "noway2019       13\n",
       "_MrUnethical    10\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we notice we still have some duplicate posts - users add spaces, punctuation, words, or CAPS to make posts different\n",
    "# I look at 'hi-volume' posters to see if we have any hi-volumen offenders.... and we DON'T!\n",
    "df.author.value_counts().loc[df.author.value_counts() >=10 ]\n",
    "# Decsion made to assume the risk of keeping duplicate posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title_selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7152</td>\n",
       "      <td>Getting pulled over for using your smartphone?...</td>\n",
       "      <td>Most state laws and local ordinances against u...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1554586946</td>\n",
       "      <td>Zer0Summoner</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>Getting pulled over for using your smartphone?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7153</td>\n",
       "      <td>Why don't Americans celebrate easter?</td>\n",
       "      <td>Don't tell me they do or you're just a filthy ...</td>\n",
       "      <td>UnethicalLifeProTips</td>\n",
       "      <td>1554595975</td>\n",
       "      <td>prototype_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>Why don't Americans celebrate easter?Don't tel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "7152  Getting pulled over for using your smartphone?...   \n",
       "7153              Why don't Americans celebrate easter?   \n",
       "\n",
       "                                               selftext             subreddit  \\\n",
       "7152  Most state laws and local ordinances against u...  UnethicalLifeProTips   \n",
       "7153  Don't tell me they do or you're just a filthy ...  UnethicalLifeProTips   \n",
       "\n",
       "      created_utc        author  num_comments  score  is_self   timestamp  \\\n",
       "7152   1554586946  Zer0Summoner             2      0     True  2019-04-06   \n",
       "7153   1554595975   prototype_4             1      1     True  2019-04-06   \n",
       "\n",
       "                                         title_selftext  \n",
       "7152  Getting pulled over for using your smartphone?...  \n",
       "7153  Why don't Americans celebrate easter?Don't tel...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create feature =  title + selftext \n",
    "df['title_selftext'] = df['title']+df['selftext']\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some very simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is histogram - character length of title\n",
    "plt.hist(df.title.str.len(), bins=20);\n",
    "# An interesting distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hisogram - character lenght of self text\n",
    "plt.hist(df.selftext.str.len(), bins=20);\n",
    "# most selftext is very short - a few outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram - number of comments\n",
    "plt.hist(df.num_comments.value_counts()  , bins=20);\n",
    "# most posts have below 25 comments - but many are very active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram - number of score\n",
    "plt.hist(df.score.value_counts()  , bins=20);\n",
    "# most posts have ow score - few outiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these have been commented out to prevent any overwriting\n",
    "\n",
    "# Our 'ethical and unethical' data\n",
    "#df.to_csv('data_eth.csv', index=False, header=True)\n",
    "\n",
    "# our 'illegal and unethical' data\n",
    "#df.to_csv('data_uneth.csv', index=False, header=True)\n",
    "\n",
    "# our 'illegal' LPT posts\n",
    "#df.to_csv('data_illegal.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in our cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 6447, 7128)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# becuase data was cleaned and saved earlier, we don't have to worry about  the risk of over-writing\n",
    "data_eth=pd.read_csv('data_eth.csv')\n",
    "data_uneth=pd.read_csv('data_uneth.csv')\n",
    "data_illegal=pd.read_csv('data_illegal.csv')\n",
    "len(data_eth), len(data_uneth), len(data_illegal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Modeling\n",
    "### Create baseline(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data= Unethical vs Ethical\n",
      "0    0.541394\n",
      "1    0.458606\n",
      "Name: subreddit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Baseline for Data1 Unethical(1) vs Ethical(0) LPT posts\n",
    "data1 = pd.concat([data_eth, data_uneth], ignore_index=True)\n",
    "data1[['subreddit']]= data1[['subreddit']].replace({'LifeProTips':0,'UnethicalLifeProTips':1})\n",
    "\n",
    "y = data1.subreddit\n",
    "X = data1.title\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "print(\"Data= Unethical vs Ethical\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "    \n",
    "# Baseline of 76.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data= Illegal vs Unethical\n",
      "1    0.525044\n",
      "0    0.474956\n",
      "Name: subreddit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Baseline for Data2 Illegal(1) vs Unethical(0) LPT posts\n",
    "data2 = pd.concat([data_uneth, data_illegal], ignore_index=True)\n",
    "data2[['subreddit']]= data2[['subreddit']].replace({'UnethicalLifeProTips':0,'IllegalLifeProTips':1})\n",
    "\n",
    "y = data2.subreddit\n",
    "X = data2.title\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "print(\"Data= Illegal vs Unethical\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "    \n",
    "# Baseline of 61.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data= Illegal vs Unethical\n",
      "0    0.516549\n",
      "1    0.483451\n",
      "Name: subreddit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Baseline for Data3 Illegal(1) vs Ethical(0) LPT posts\n",
    "data3 = pd.concat([data_eth, data_illegal], ignore_index=True)\n",
    "data3[['subreddit']]= data3[['subreddit']].replace({'LifeProTips':0,'IllegalLifeProTips':1})\n",
    "\n",
    "y = data3.subreddit\n",
    "X = data3.title\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "print(\"Data= Illegal vs Unethical\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "    \n",
    "# Baseline of 66.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Data Modeling\n",
    "## 3.1 Data 1 - Predicting Unethical vs Ethical Life Pro Tips\n",
    "### 3.1.1 Model 1.1 = Vectorizers and LogReg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE PIPES for Vectorizers and Logreg\n",
    "\n",
    "# Vectorizer features\n",
    "my_max_features=[1200,1500]  # these features fine-tuned \n",
    "my_stop_words=[None]  #'english' stopwords removed, not significant\n",
    "my_ngram_range=[(1,1),(1,2)]\n",
    "my_min_df= [1,2] \n",
    "#my_max_df=[0.80, 0.90]  # this was not significant\n",
    "\n",
    "\n",
    "# pipe and parameters for cvec\n",
    "pipeC = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "    \n",
    "pipeC_params = {\n",
    "    'cvec__max_features': my_max_features,\n",
    "    'cvec__min_df': my_min_df,\n",
    "    #'cvec__max_df': my_max_df,\n",
    "    'cvec__stop_words': my_stop_words,\n",
    "    'cvec__ngram_range': my_ngram_range\n",
    "    }\n",
    "    \n",
    "\n",
    "# pipe and parameters for tvec\n",
    "pipeT = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "\n",
    "pipeT_params = {\n",
    "    'tvec__max_features': my_max_features,\n",
    "    'tvec__min_df': my_min_df,\n",
    "    #'tvec__max_df': my_max_df,    # not significant\n",
    "    'tvec__stop_words': my_stop_words,\n",
    "    'tvec__ngram_range': my_ngram_range,\n",
    "    }\n",
    " \n",
    "my_data=['title','selftext']  #selftext and title_selftext removed\n",
    "my_pipes=[pipeT,pipeC]  # PipeC removed\n",
    "my_pipeparams=[pipeT_params,pipeC_params]\n",
    "my_pipenames = ['TVectorizer','Cvec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data1 title\n",
      "Model = TVectorizer\n",
      "GridSearch best params = \n",
      "{'tvec__max_features': 1500, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 1), 'tvec__stop_words': None}\n",
      "GridSearch best score = 0.7751541014698909\n",
      "GS train score = 0.82475106685633\n",
      "GS test score  = 0.7817923186344239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data1 title\n",
      "Model = Cvec\n",
      "GridSearch best params = \n",
      "{'cvec__max_features': 1200, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None}\n",
      "GridSearch best score = 0.7655761024182077\n",
      "GS train score = 0.8304409672830726\n",
      "GS test score  = 0.761877667140825\n",
      "\n",
      "Data1 selftext\n",
      "Model = TVectorizer\n",
      "GridSearch best params = \n",
      "{'tvec__max_features': 1500, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 1), 'tvec__stop_words': None}\n",
      "GridSearch best score = 0.7519203413940256\n",
      "GS train score = 0.811284969179706\n",
      "GS test score  = 0.748221906116643\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\msgig\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data1 selftext\n",
      "Model = Cvec\n",
      "GridSearch best params = \n",
      "{'cvec__max_features': 1500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None}\n",
      "GridSearch best score = 0.7266002844950213\n",
      "GS train score = 0.8209577999051684\n",
      "GS test score  = 0.7280227596017069\n",
      "\n",
      "Baseline= \n",
      "0    0.541394\n",
      "1    0.458606\n",
      "Name: subreddit, dtype: float64\n",
      "Model 1, data1 = Predicting Unethical vs Ethical Life Pro Tips, using vectorizers and logreg\n"
     ]
    }
   ],
   "source": [
    "# Loops designed to iterate thru various models to find best fit\n",
    "\n",
    "for j in my_data:\n",
    "\n",
    "    X = data1[j]\n",
    "    y = data1['subreddit']      \n",
    "    X_train, X_test, y_train, y_test = (train_test_split(X, y,random_state=42, stratify=y))\n",
    "\n",
    "    for i in range(0,len(my_pipenames)):\n",
    "\n",
    "        gs = GridSearchCV(my_pipes[i], param_grid=my_pipeparams[i], cv=3) \n",
    "        gs.fit(X_train, y_train)\n",
    "        gs_bestmodel = gs.best_estimator_\n",
    "    \n",
    "        print(f\"Data1 {j}\")\n",
    "        print(f\"Model = {my_pipenames[i]}\")\n",
    "        print(f\"GridSearch best params = \\n{gs.best_params_}\")\n",
    "        print(f\"GridSearch best score = {gs.best_score_}\")\n",
    "        print(f\"GS train score = {gs_bestmodel.score(X_train, y_train)}\")\n",
    "        print(f\"GS test score  = {gs_bestmodel.score(X_test, y_test)}\")\n",
    "        print()\n",
    " \n",
    "print(f\"Baseline= \\n{y_test.value_counts(normalize=True)}\")  \n",
    "print(f\"Model 1, data1 = Predicting Unethical vs Ethical Life Pro Tips, using vectorizers and logreg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.1 ,Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                      Predicted N (ethical)  Predicted P (Unethical)\n",
      "Actual N (ethical)                     1595                      308\n",
      "Actual P (Unethical)                    459                     1153\n",
      "\n",
      "Sensitivity = 0.7152605459057072\n",
      "Specificity = 0.838150289017341\n",
      "Accuracy = 0.7817923186344239\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_bestmodel.fit(X_train, y_train).predict(X_test) \n",
    "cm = confusion_matrix(y_test, y_pred)  # matrix of actual y and predicted y\n",
    "cm_df = pd.DataFrame(cm, columns=['Predicted N (ethical)', 'Predicted P (Unethical)'],index=['Actual N (ethical)', 'Actual P (Unethical)'])\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Confusion Matrix:')\n",
    "print(cm_df)\n",
    "print()\n",
    "print(f\"Sensitivity = {tp / (tp + fn)}\")\n",
    "print(f\"Specificity = {tn/(tn+fp)}\")\n",
    "print(f\"Accuracy = {(tp+tn)/(tp+tn+fp+fn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.2 = data1, Vectorizer and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NBmodel = Bernoulli\n",
      " train score = 0.7889995258416311\n",
      " test score  = 0.7647226173541963\n",
      "\n",
      "NBmodel = Multinomial\n",
      " train score = 0.8006638217164533\n",
      " test score  = 0.7752489331436699\n",
      "\n",
      "Baseline= \n",
      "0    0.541394\n",
      "1    0.458606\n",
      "Name: subreddit, dtype: float64\n",
      "Model 2 , data2, predicting unethical vs ethical LPT with Tvec/NB\n"
     ]
    }
   ],
   "source": [
    "my_NBmodels=[BernoulliNB(), MultinomialNB()]\n",
    "my_NBmodelnames=['Bernoulli','Multinomial']\n",
    "\n",
    "X = data1.title  # our best data\n",
    "y = data1.subreddit\n",
    "X_train, X_test, y_train, y_test = (train_test_split(X, y,random_state=42,stratify=y))\n",
    "\n",
    "#Taking our 'best' model from above\n",
    "tvec = TfidfVectorizer(max_features= 1500, ngram_range= (1, 1), stop_words=None, )\n",
    "\n",
    "X_train = tvec.fit_transform(X_train).toarray()\n",
    "X_test = tvec.transform(X_test).toarray()\n",
    "print()\n",
    "\n",
    "for i in range(0,len(my_NBmodelnames)):\n",
    "    nb = my_NBmodels[i]\n",
    "    y_pred = nb.fit(X_train, y_train).predict(X_test)   \n",
    "    \n",
    "    print(f\"NBmodel = {my_NBmodelnames[i]}\")\n",
    "    print(f\" train score = {nb.score(X_train, y_train)}\")\n",
    "    print(f\" test score  = {nb.score(X_test, y_test)}\")\n",
    "    print()\n",
    "    \n",
    "print(f\"Baseline= \\n{y_test.value_counts(normalize=True)}\")    \n",
    "print(f\"Model 2 , data2, predicting unethical vs ethical LPT with Tvec/NB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                      Predicted N (ethical)  Predicted P (Unethical)\n",
      "Actual N (ethical)                     1579                      324\n",
      "Actual P (Unethical)                    466                     1146\n",
      "\n",
      "Sensitivity = 0.7109181141439206\n",
      "Specificity = 0.8297425118234367\n",
      "Accuracy = 0.7752489331436699\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb.fit(X_train, y_train).predict(X_test) \n",
    "cm = confusion_matrix(y_test, y_pred)  # matrix of actual y and predicted y\n",
    "cm_df = pd.DataFrame(cm, columns=['Predicted N (ethical)', 'Predicted P (Unethical)'], \n",
    "                     index=['Actual N (ethical)', 'Actual P (Unethical)'])\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Confusion Matrix:')\n",
    "print(cm_df)\n",
    "print()\n",
    "print(f\"Sensitivity = {tp / (tp + fn)}\")\n",
    "print(f\"Specificity = {tn/(tn+fp)}\")\n",
    "print(f\"Accuracy = {(tp+tn)/(tp+tn+fp+fn)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Model 1 \n",
    ">### GENERAL FINDINGS for all 3 datasets - \n",
    ">- **Title has more 'weight' than selftext.** In ALL 3 datasets the TITLE yielded the highest scores for accuracy as compared to selftext and title_selftext combo.  Indeed, selftext generated non-convergence warnings.  I suspect this is because the titles were generally very descriptive. \n",
    ">- **Tvec is more accurate than Cvec.**  In ALL 3 datasets, Tvec yeilded consistently slightly higher scores and when pushed for tuning Cvec often generated non-convergence warnings.\n",
    ">- **LogReg is more accurate than Naive Bayes.**  In ALL 3 datasets LogReg was slightly more accurate than NB.  In addition, in ALL 3 datasets, MultinomialNB is slightly more accurate than BinomialNB.  ALthough NB generated slightly less accurate models than LogReg, its overfit was slightly less, but its results were consistenly skewed to higher SPECIFICITY (not SENSITIVITY).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.2 Modelling Data 2 - Predicting Illegal vs Unethical Life Pro Tips\n",
    "###  Model 2.1 = data 2  ,  Vectorizers and LogReg (and SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer features\n",
    "my_max_features=[1100,1200]  # these features fine-tuned \n",
    "my_stop_words=[None]  #'english' stopwords removed, not significant\n",
    "my_ngram_range=[(1,1),(1,2)]\n",
    "my_min_df= [2,3] \n",
    "#my_max_df=[0.80, 0.90]  # this was not significant\n",
    "\n",
    "\n",
    "# SVC features  MORE ON SVC LATER\n",
    "my_C= [1,5,10, 20]\n",
    "my_kernel=['linear','rbf']\n",
    "my_gamma= ['auto','scale']\n",
    "\n",
    "\n",
    "# pipe and parameters for cvec\n",
    "#pipeC = Pipeline([\n",
    "    #('cvec', CountVectorizer()),\n",
    "    #('logreg', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "#pipeC2 = Pipeline([\n",
    "    #('cvec', CountVectorizer()),\n",
    "    #('svc', SVC())]) \n",
    "    \n",
    "#pipeC_params = {\n",
    "    #'cvec__max_features': my_max_features,\n",
    "    #'cvec__min_df': my_min_df,\n",
    "    #'cvec__max_df': my_max_df,\n",
    "    #'cvec__stop_words': my_stop_words,\n",
    "    #'cvec__ngram_range': my_ngram_range,\n",
    "    #'svc__C': my_C,\n",
    "    #'svc__kernel': my_kernel,\n",
    "    #'svc__gamma': my_gamma\n",
    "    #}\n",
    "    \n",
    "\n",
    "# pipe and parameters for tvec\n",
    "pipeT = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "#pipeT2 = Pipeline([\n",
    "    #('tvec', TfidfVectorizer()),\n",
    "    #('svc', SVC())])\n",
    "\n",
    "\n",
    "pipeT_params = {\n",
    "    'tvec__max_features': my_max_features,\n",
    "    'tvec__min_df': my_min_df,\n",
    "    #'tvec__max_df': my_max_df,    \n",
    "    'tvec__stop_words': my_stop_words,\n",
    "    'tvec__ngram_range': my_ngram_range,\n",
    "    #'svc__C': my_C,\n",
    "    #'svc__kernel': my_kernel,\n",
    "    #'svc__gamma': my_gamma\n",
    "    }\n",
    " \n",
    "my_data=['title']  #selftext and title_selftext removed due to non-convergence\n",
    "my_pipes=[pipeT]  # PipeC removed due to lower score/higher overfit\n",
    "my_pipeparams=[pipeT_params]\n",
    "my_pipenames = ['TVectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data2 title\n",
      "Model = TVectorizer\n",
      "GridSearch best params = \n",
      "{'tvec__max_features': 1200, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 1), 'tvec__stop_words': None}\n",
      "GridSearch best score = 0.7645614379726943\n",
      "GS train score = 0.8099400844710736\n",
      "GS test score  = 0.7604596346493813\n",
      "\n",
      "Baseline= \n",
      "1    0.525044\n",
      "0    0.474956\n",
      "Name: subreddit, dtype: float64\n",
      "Model 2 , data2 = Predicting Illegal vs Unethical Life Pro Tips, using vectorizers and logreg\n"
     ]
    }
   ],
   "source": [
    "for j in my_data:\n",
    "\n",
    "    X = data2[j]\n",
    "    y = data2['subreddit']   \n",
    "    X_train, X_test, y_train, y_test = (train_test_split(X, y,random_state=42,stratify=y))\n",
    "\n",
    "    for i in range(0,len(my_pipenames)):\n",
    "\n",
    "        gs = GridSearchCV(my_pipes[i],param_grid=my_pipeparams[i],cv=3) \n",
    "        gs.fit(X_train, y_train)\n",
    "        gs_bestmodel = gs.best_estimator_\n",
    "    \n",
    "        print(f\"Data2 {j}\")\n",
    "        print(f\"Model = {my_pipenames[i]}\")\n",
    "        print(f\"GridSearch best params = \\n{gs.best_params_}\")  \n",
    "        print(f\"GridSearch best score = {gs.best_score_}\")\n",
    "        print(f\"GS train score = {gs_bestmodel.score(X_train, y_train)}\")\n",
    "        print(f\"GS test score  = {gs_bestmodel.score(X_test, y_test)}\")\n",
    "        print()\n",
    " \n",
    "print(f\"Baseline= \\n{y_test.value_counts(normalize=True)}\")  \n",
    "print(f\"Model 2 , data2 = Predicting Illegal vs Unethical Life Pro Tips, using vectorizers and logreg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2.1, confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                      Predicted N (unethical)  Predicted P (Illegal)\n",
      "Actual N (unethical)                     1156                    456\n",
      "Actual P (Illegal)                        357                   1425\n",
      "\n",
      "Sensitivity = 0.7996632996632996\n",
      "Specificity = 0.71712158808933\n",
      "Accuracy = 0.7604596346493813\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_bestmodel.fit(X_train, y_train).predict(X_test) \n",
    "cm = confusion_matrix(y_test, y_pred)  # matrix of actual y and predicted y\n",
    "cm_df = pd.DataFrame(cm, columns=['Predicted N (unethical)', 'Predicted P (Illegal)'], \n",
    "                     index=['Actual N (unethical)', 'Actual P (Illegal)'])\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Confusion Matrix:')\n",
    "print(cm_df)\n",
    "print()\n",
    "print(f\"Sensitivity = {tp / (tp + fn)}\")\n",
    "print(f\"Specificity = {tn/(tn+fp)}\")\n",
    "print(f\"Accuracy = {(tp+tn)/(tp+tn+fp+fn)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2.2 =  data2, vectorizer and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NBmodel = Bernoulli\n",
      " train score = 0.7399076711521462\n",
      " test score  = 0.7292280494991161\n",
      "\n",
      "NBmodel = Multinomial\n",
      " train score = 0.779687653472154\n",
      " test score  = 0.7457277548615203\n",
      "\n",
      "Baseline= \n",
      "1    0.525044\n",
      "0    0.474956\n",
      "Name: subreddit, dtype: float64\n",
      "Model 2 = Ethical/ unethical with Tvec/NB\n"
     ]
    }
   ],
   "source": [
    "my_NBmodels=[BernoulliNB(), MultinomialNB()]\n",
    "my_NBmodelnames=['Bernoulli','Multinomial']\n",
    "\n",
    "X = data2.title  # our best data\n",
    "y = data2.subreddit\n",
    "X_train, X_test, y_train, y_test = (train_test_split(X, y,random_state=42,stratify=y))\n",
    "\n",
    "#Taking our 'best' model from above\n",
    "tvec = TfidfVectorizer(max_features= 1200, min_df= 2, ngram_range= (1, 2), stop_words=None, )\n",
    "\n",
    "X_train = tvec.fit_transform(X_train).toarray()\n",
    "X_test = tvec.transform(X_test).toarray()\n",
    "print()\n",
    "\n",
    "for i in range(0,len(my_NBmodelnames)):\n",
    "    nb = my_NBmodels[i]\n",
    "    y_pred = nb.fit(X_train, y_train).predict(X_test)   \n",
    "    \n",
    "    print(f\"NBmodel = {my_NBmodelnames[i]}\")\n",
    "    print(f\" train score = {nb.score(X_train, y_train)}\")\n",
    "    print(f\" test score  = {nb.score(X_test, y_test)}\")\n",
    "    print()\n",
    "    \n",
    "print(f\"Baseline= \\n{y_test.value_counts(normalize=True)}\")    \n",
    "print(f\"Model 2 = Ethical/ unethical with Tvec/NB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                      Predicted N (unethical)  Predicted P (Illegal)\n",
      "Actual N (unethical)                     1115                    497\n",
      "Actual P (Illegal)                        366                   1416\n",
      "\n",
      "Sensitivity = 0.7946127946127947\n",
      "Specificity = 0.6916873449131513\n",
      "Accuracy = 0.7457277548615203\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb.fit(X_train, y_train).predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  # matrix of actual y and predicted y\n",
    "cm_df = pd.DataFrame(cm, columns=['Predicted N (unethical)', 'Predicted P (Illegal)'], \n",
    "                     index=['Actual N (unethical)', 'Actual P (Illegal)'])\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Confusion Matrix:')\n",
    "print(cm_df)\n",
    "print()\n",
    "print(f\"Sensitivity = {tp / (tp + fn)}\")\n",
    "print(f\"Specificity = {tn/(tn+fp)}\")\n",
    "print(f\"Accuracy = {(tp+tn)/(tp+tn+fp+fn)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2.3 = data 2 and Vectorizer and SVC¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### switched to markdown to avoid excessivly loooooong runs\n",
    "### Click to see code\n",
    "\n",
    "#pipe and parameters for tvec\n",
    "pipeTsvc = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('svc', SVC())])\n",
    "\n",
    "\n",
    "pipeT_params = {\n",
    "    'tvec__max_features': my_max_features,\n",
    "    'tvec__min_df': my_min_df,\n",
    "    #'tvec__max_df': my_max_df,    \n",
    "    'tvec__stop_words': my_stop_words,\n",
    "    'tvec__ngram_range': my_ngram_range,\n",
    "    'svc__C': my_C,\n",
    "    'svc__kernel': my_kernel,\n",
    "    'svc__gamma': my_gamma\n",
    "    }\n",
    "\n",
    "#Vectorizer features\n",
    "my_max_features=[1200]  # these features fine-tuned \n",
    "my_stop_words=[None]  #'english' stopwords removed, not significant\n",
    "my_ngram_range=[(1,2)]\n",
    "my_min_df= [2] \n",
    "#my_max_df=[0.80, 0.90]  # this was not significant\n",
    "\n",
    "\n",
    "#SVC features\n",
    "my_C= [1]\n",
    "my_kernel=['rbf']\n",
    "my_gamma= ['scale']\n",
    "\n",
    "    \n",
    "my_data=['title']  #selftext and title_selftext removed due to non-convergence\n",
    "my_pipes=[pipeTsvc]  # PipeC removed due to lower score/higher overfit\n",
    "my_pipeparams=[pipeT_params]\n",
    "my_pipenames = ['TVec_SVC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click to see code\n",
    "\n",
    "for j in my_data:\n",
    "\n",
    "    X = data2[j]\n",
    "    y = data2['subreddit']   \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = (train_test_split(X, y,random_state=42,stratify=y))\n",
    "\n",
    "    for i in range(0,len(my_pipenames)):\n",
    "\n",
    "        gs = GridSearchCV(my_pipes[i], \n",
    "                  param_grid=my_pipeparams[i], \n",
    "                  cv=3) \n",
    "        gs.fit(X_train, y_train)\n",
    "        gs_bestmodel = gs.best_estimator_\n",
    "    \n",
    "        print(f\"Data2 {j}\")\n",
    "        print(f\"Model = {my_pipenames[i]}\")\n",
    "        print(f\"GridSearch best params = \\n{gs.best_params_}\") \n",
    "        print(f\"GridSearch best score = {gs.best_score_}\")\n",
    "        print(f\"GS train score = {gs_bestmodel.score(X_train, y_train)}\")\n",
    "        print(f\"GS test score  = {gs_bestmodel.score(X_test, y_test)}\")\n",
    "        print()\n",
    " \n",
    "print(f\"Baseline= \\n{y_test.value_counts(normalize=True)}\")  \n",
    "print(f\"Model 2 , data2 = Predicting Illegal vs Unethical Life Pro Tips, using vectorizers and logreg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of 'best' SVC model\n",
    "\n",
    "**Data2 title**\n",
    "**Model = TVec_SVC**\n",
    "- GridSearch best params = \n",
    "- {'svc__C': 1, 'svc__gamma': 'scale', 'svc__kernel': 'rbf', 'tvec__max_features': 1200, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 1), 'tvec__stop_words': None}\n",
    "- GridSearch best score = 0.7676063255082998\n",
    "- GS train score = 0.9207347018956881\n",
    "- GS test score  = 0.7622274602239246\n",
    "\n",
    "**Baseline=** \n",
    "- 1    0.525044\n",
    "- 0    0.474956\n",
    "- Name: subreddit, dtype: float64\n",
    "- Model 2 , data2 = Predicting Illegal vs Unethical Life Pro Tips, using vectorizers and logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Model 2\n",
    ">### GENERAL FINDINGS for all 3 datasets\n",
    ">- ALthough only shown in Model2/Data2, the following finding are for ALL 3 datasets.\n",
    ">- **LogReg accuracy comparable to SVC Model but at a FRACTION of the time and CPU.**  Although SVC yielded similar Accuracy to LegReg, its overfit on the Train data was consistently much higher.\n",
    ">- Code above is in markdown to prevent costly execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.3 Modeling Data 3 - Predicting Illegal vs Ethical Life Pro Tips\n",
    "### Model 3.1 = data 3, Vectorizers and LogReg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIPES\n",
    "# Vectorizer features\n",
    "my_max_features=[1800,2000]  # these features fine-tuned \n",
    "my_stop_words=[None]  #'english' stopwords removed, not significant\n",
    "my_ngram_range=[(1,1),(1,2)]\n",
    "my_min_df= [2,3,4] \n",
    "#my_max_df=[0.80, 0.90]  # this was not significant  \n",
    "\n",
    "#pipe and parameters for cvec\n",
    "#pipeC = Pipeline([\n",
    "    #('cvec', CountVectorizer()),\n",
    "    #('logreg', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "#pipeC_params = {\n",
    "    #'cvec__max_features': my_max_features,\n",
    "    #'cvec__min_df': my_min_df,\n",
    "    #'cvec__max_df': my_max_df,\n",
    "    #'cvec__stop_words': my_stop_words,\n",
    "    #'cvec__ngram_range': my_ngram_range\n",
    "    #}\n",
    "    \n",
    "\n",
    "#pipe and parameters for tvec\n",
    "pipeT = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "pipeT_params = {\n",
    "    'tvec__max_features': my_max_features,\n",
    "    'tvec__min_df': my_min_df,\n",
    "    #'tvec__max_df': my_max_df,    \n",
    "    'tvec__stop_words': my_stop_words,\n",
    "    'tvec__ngram_range': my_ngram_range\n",
    "    }\n",
    "   \n",
    "my_data=['title']  #selftext and title_selftext removed due to non-convergence\n",
    "my_pipes=[pipeT]  # PipeC removed due to lower score/higher overfit\n",
    "my_pipeparams=[pipeT_params]\n",
    "my_pipenames = ['TVectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data3 title\n",
      "Model = TVectorizer\n",
      "GridSearch best params = \n",
      "{'tvec__max_features': 2000, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 1), 'tvec__stop_words': None}\n",
      "GridSearch best score = 0.8903663500678426\n",
      "GS train score = 0.9210312075983718\n",
      "GS test score  = 0.8982637004883343\n",
      "\n",
      "Baseline= \n",
      "0    0.516549\n",
      "1    0.483451\n",
      "Name: subreddit, dtype: float64\n",
      "Model 3 , data3 = Predicting Illegal vs Ethical LPTs using vectorizers and logreg\n"
     ]
    }
   ],
   "source": [
    "for j in my_data:\n",
    "\n",
    "    X = data3[j]\n",
    "    y = data3['subreddit']\n",
    "    X_train, X_test, y_train, y_test = (train_test_split(X, y,random_state=42,stratify=y))\n",
    "\n",
    "    for i in range(0,len(my_pipenames)):\n",
    "\n",
    "        gs = GridSearchCV(my_pipes[i], param_grid=my_pipeparams[i], cv=3)  \n",
    "        gs.fit(X_train, y_train)\n",
    "        gs_bestmodel = gs.best_estimator_\n",
    "    \n",
    "        print(f\"Data3 {j}\")\n",
    "        print(f\"Model = {my_pipenames[i]}\")\n",
    "        print(f\"GridSearch best params = \\n{gs.best_params_}\")\n",
    "        print(f\"GridSearch best score = {gs.best_score_}\")\n",
    "        print(f\"GS train score = {gs_bestmodel.score(X_train, y_train)}\")\n",
    "        print(f\"GS test score  = {gs_bestmodel.score(X_test, y_test)}\")\n",
    "        print()\n",
    " \n",
    "print(f\"Baseline= \\n{y_test.value_counts(normalize=True)}\")  \n",
    "print(f\"Model 3 , data3 = Predicting Illegal vs Ethical LPTs using vectorizers and logreg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3.1 , Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                    Predicted N (ethical)  Predicted P (Illegal)\n",
      "Actual N (ethical)                   1722                    182\n",
      "Actual P (Illegal)                    193                   1589\n",
      "\n",
      "Sensitivity = 0.8916947250280584\n",
      "Specificity = 0.9044117647058824\n",
      "Accuracy = 0.8982637004883343\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_bestmodel.fit(X_train, y_train).predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  # matrix of actual y and predicted y\n",
    "cm_df = pd.DataFrame(cm, columns=['Predicted N (ethical)', 'Predicted P (Illegal)'], \n",
    "                     index=['Actual N (ethical)', 'Actual P (Illegal)'])\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Confusion Matrix:')\n",
    "print(cm_df)\n",
    "print()\n",
    "print(f\"Sensitivity = {tp / (tp + fn)}\")\n",
    "print(f\"Specificity = {tn/(tn+fp)}\")\n",
    "print(f\"Accuracy = {(tp+tn)/(tp+tn+fp+fn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_values</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3373</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4569</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       true_values  pred_probs\n",
       "3373             0    0.070659\n",
       "4569             0    0.172704\n",
       "1975             0    0.023133\n",
       "10723            1    0.049737\n",
       "10515            1    0.781980"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = [i[1] for i in gs_bestmodel.predict_proba(X_test)]\n",
    "\n",
    "pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544057521998698"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's get our ROC score\n",
    "roc_auc_score(pred_df['true_values'], pred_df['pred_probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure for ROC to get an idea of sensitivity and specificity tradeoff\n",
    "# this code is was provided in class\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create threshold values. (Dashed red line in image.)\n",
    "thresholds = np.linspace(0, 1, 200)\n",
    "\n",
    "# Define function to calculate sensitivity. (True positive rate.)\n",
    "def TPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_positive = df[(df[true_col] == 1) & (df[pred_prob_col] >= threshold)].shape[0]\n",
    "    false_negative = df[(df[true_col] == 1) & (df[pred_prob_col] < threshold)].shape[0]\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "    \n",
    "\n",
    "# Define function to calculate 1 - specificity. (False positive rate.)\n",
    "def FPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_negative = df[(df[true_col] == 0) & (df[pred_prob_col] <= threshold)].shape[0]\n",
    "    false_positive = df[(df[true_col] == 0) & (df[pred_prob_col] > threshold)].shape[0]\n",
    "    return 1 - (true_negative / (true_negative + false_positive))\n",
    "    \n",
    "# Calculate sensitivity & 1-specificity for each threshold between 0 and 1.\n",
    "tpr_values = [TPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "fpr_values = [FPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "\n",
    "# Plot ROC curve.\n",
    "plt.plot(fpr_values, # False Positive Rate on X-axis\n",
    "         tpr_values, # True Positive Rate on Y-axis\n",
    "         label='ROC Curve')\n",
    "\n",
    "# Plot baseline. (Perfect overlap between the two populations.)\n",
    "plt.plot(np.linspace(0, 1, 200),\n",
    "         np.linspace(0, 1, 200),\n",
    "         label='baseline',\n",
    "         linestyle='--')\n",
    "\n",
    "# Label axes.\n",
    "plt.title(f'ROC Curve with AUC = {round(roc_auc_score(pred_df[\"true_values\"], pred_df[\"pred_probs\"]),3)}', fontsize=22)\n",
    "plt.ylabel('Sensitivity', fontsize=18)\n",
    "plt.xlabel('1 - Specificity', fontsize=18)\n",
    "\n",
    "# Create legend.\n",
    "plt.legend(fontsize=16);\n",
    "          \n",
    "# curve looks good,a fair bit of separate for our two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3.2 = data3,  Vectorizer and NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NBmodel = Bernoulli\n",
      " train score = 0.860153776571687\n",
      " test score  = 0.8480737927292458\n",
      "\n",
      "NBmodel = Multinomial\n",
      " train score = 0.9075531433740389\n",
      " test score  = 0.887683125339121\n",
      "\n",
      "Baseline= \n",
      "0    0.516549\n",
      "1    0.483451\n",
      "Name: subreddit, dtype: float64\n",
      "Model 2 = Ethical/ unethical with Tvec/NB\n"
     ]
    }
   ],
   "source": [
    "my_NBmodels=[BernoulliNB(), MultinomialNB()]\n",
    "my_NBmodelnames=['Bernoulli','Multinomial']\n",
    "\n",
    "X = data3.title  # our best data\n",
    "y = data3.subreddit\n",
    "X_train, X_test, y_train, y_test = (train_test_split(X, y,random_state=42,stratify=y))\n",
    "\n",
    "#Taking our 'best' model from above\n",
    "tvec = TfidfVectorizer(max_features= 2000, ngram_range= (1, 1), stop_words=None, )\n",
    "\n",
    "X_train = tvec.fit_transform(X_train).toarray()\n",
    "X_test = tvec.transform(X_test).toarray()\n",
    "print()\n",
    "\n",
    "for i in range(0,len(my_NBmodelnames)):\n",
    "    nb = my_NBmodels[i]\n",
    "    y_pred = nb.fit(X_train, y_train).predict(X_test)   \n",
    "    \n",
    "    print(f\"NBmodel = {my_NBmodelnames[i]}\")\n",
    "    print(f\" train score = {nb.score(X_train, y_train)}\")\n",
    "    print(f\" test score  = {nb.score(X_test, y_test)}\")\n",
    "    print()\n",
    "    \n",
    "print(f\"Baseline= \\n{y_test.value_counts(normalize=True)}\")    \n",
    "print(f\"Model 2 = Ethical/ unethical with Tvec/NB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                    Predicted N (ethical)  Predicted P (Illegal)\n",
      "Actual N (ethical)                   1743                    161\n",
      "Actual P (Illegal)                    253                   1529\n",
      "\n",
      "Sensitivity = 0.8580246913580247\n",
      "Specificity = 0.9154411764705882\n",
      "Accuracy = 0.887683125339121\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb.fit(X_train, y_train).predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  # matrix of actual y and predicted y\n",
    "cm_df = pd.DataFrame(cm, columns=['Predicted N (ethical)', 'Predicted P (Illegal)'], \n",
    "                     index=['Actual N (ethical)', 'Actual P (Illegal)'])\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Confusion Matrix:')\n",
    "print(cm_df)\n",
    "print()\n",
    "print(f\"Sensitivity = {tp / (tp + fn)}\")\n",
    "print(f\"Specificity = {tn/(tn+fp)}\")\n",
    "print(f\"Accuracy = {(tp+tn)/(tp+tn+fp+fn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3.3 = data3,  Vectorizer and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIPES\n",
    "\n",
    "#pipe and parameters for tvec\n",
    "pipeT = Pipeline([\n",
    "    ('tvec', TfidfVectorizer( max_features=600,stop_words=None )),\n",
    "    ('dt', DecisionTreeClassifier(random_state = 42))\n",
    "    ])\n",
    "\n",
    "pipeT_params = {\n",
    "            'dt__max_depth': [60,70],\n",
    "            'dt__min_samples_split': [60,70],\n",
    "            'dt__min_samples_leaf': [3, 5]\n",
    "            }\n",
    "    \n",
    "my_data=['title']  #selftext and title_selftext removed due to non-convergence\n",
    "my_pipes=[pipeT]  # PipeC removed due to lower score/higher overfit\n",
    "my_pipeparams=[pipeT_params]\n",
    "my_pipenames = ['TVec_Dtree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data3 title\n",
      "Model = TVec_Dtree\n",
      "GridSearch best params = \n",
      "{'dt__max_depth': 60, 'dt__min_samples_leaf': 5, 'dt__min_samples_split': 60}\n",
      "GridSearch best score = 0.8255088195386703\n",
      "GS train score = 0.8850293984622343\n",
      "GS test score  = 0.8260987520347259\n",
      "\n",
      "Baseline= \n",
      "0    0.516549\n",
      "1    0.483451\n",
      "Name: subreddit, dtype: float64\n",
      "Model 3 , data3 = Predicting Illegal vs Ethical LPTs using vectorizers and logreg\n"
     ]
    }
   ],
   "source": [
    "for j in my_data:\n",
    "\n",
    "    X = data3[j]\n",
    "    y = data3['subreddit']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = (train_test_split(X, y, \n",
    "                                random_state=42, \n",
    "                                stratify=y))\n",
    "\n",
    "    for i in range(0,len(my_pipenames)):\n",
    "\n",
    "        gs = GridSearchCV(my_pipes[i], param_grid=my_pipeparams[i], cv=3 )  \n",
    "        gs.fit(X_train, y_train)\n",
    "        gs_bestmodel = gs.best_estimator_\n",
    "    \n",
    "        print(f\"Data3 {j}\")\n",
    "        print(f\"Model = {my_pipenames[i]}\")\n",
    "        print(f\"GridSearch best params = \\n{gs.best_params_}\")\n",
    "        print(f\"GridSearch best score = {gs.best_score_}\")\n",
    "        print(f\"GS train score = {gs_bestmodel.score(X_train, y_train)}\")\n",
    "        print(f\"GS test score  = {gs_bestmodel.score(X_test, y_test)}\")\n",
    "        print()\n",
    " \n",
    "print(f\"Baseline= \\n{y_test.value_counts(normalize=True)}\")  \n",
    "print(f\"Model 3 , data3 = Predicting Illegal vs Ethical LPTs using vectorizers and logreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                    Predicted N (ethical)  Predicted P (Illegal)\n",
      "Actual N (ethical)                   1588                    316\n",
      "Actual P (Illegal)                    325                   1457\n",
      "\n",
      "Sensitivity = 0.8176206509539843\n",
      "Specificity = 0.8340336134453782\n",
      "Accuracy = 0.8260987520347259\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_bestmodel.fit(X_train, y_train).predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  # matrix of actual y and predicted y\n",
    "cm_df = pd.DataFrame(cm, columns=['Predicted N (ethical)', 'Predicted P (Illegal)'], \n",
    "                     index=['Actual N (ethical)', 'Actual P (Illegal)'])\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Confusion Matrix:')\n",
    "print(cm_df)\n",
    "print()\n",
    "print(f\"Sensitivity = {tp / (tp + fn)}\")\n",
    "print(f\"Specificity = {tn/(tn+fp)}\")\n",
    "print(f\"Accuracy = {(tp+tn)/(tp+tn+fp+fn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If I wanted to create output for decsion tree, I'd have to vectorize the x data and save to array prior to running this function .. maybe later...\n",
    "\n",
    "\n",
    "pd.DataFrame(resulting_sparse_matrix.toarray(), columns = tfidf_instance.get_feature_names())\n",
    "\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(dt,\n",
    "               out_file=\"./test.dot\",\n",
    "               feature_names=X_train.columns,\n",
    "               class_names=['not survived','survived'],\n",
    "               rounded=True,\n",
    "               filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there key words influencing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopword ethical is found 7 times in Data3 title\n",
      "Stopword unethical is found 3 times in Data3 title\n",
      "Stopword legal is found 153 times in Data3 title\n",
      "Stopword illegal is found 86 times in Data3 title\n",
      "Stopword evil is found 5 times in Data3 title\n",
      "Stopword bad is found 107 times in Data3 title\n"
     ]
    }
   ],
   "source": [
    "# I suspect some specific words may be triggering the high rate of prediction\n",
    "my_stopwords=['ethical','unethical','legal','illegal','evil','bad', ]\n",
    "my_data = ['title']\n",
    "\n",
    "for j in my_stopwords:\n",
    "    for i in my_data:\n",
    "        print(f\"Stopword {j} is found {data3[i].str.count(j).sum() } times in Data3 {i}\")\n",
    "        \n",
    "# Wow, out of 14k of posts, am surprise there were so few of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use cvec to get a lists of words and value counts!\n",
    "X = data3.title_selftext\n",
    "y = data3.subreddit\n",
    "X_train, X_test, y_train, y_test = (train_test_split(X, y,random_state=42,stratify=y))\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')   \n",
    "cv_fit=cv.fit_transform(X_train,y_train)    \n",
    "word_list = cv.get_feature_names()\n",
    "count_list = cv_fit.toarray().sum(axis=0).tolist()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30295</td>\n",
       "      <td>𝙩𝙧𝙮𝙞𝙣𝙜</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14137</td>\n",
       "      <td>initiated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14138</td>\n",
       "      <td>initiates</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14139</td>\n",
       "      <td>initiation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14142</td>\n",
       "      <td>injected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16451</td>\n",
       "      <td>make</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29179</td>\n",
       "      <td>want</td>\n",
       "      <td>2667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15861</td>\n",
       "      <td>like</td>\n",
       "      <td>3135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8808</td>\n",
       "      <td>don</td>\n",
       "      <td>3613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15023</td>\n",
       "      <td>just</td>\n",
       "      <td>4174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30296 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  count\n",
       "30295      𝙩𝙧𝙮𝙞𝙣𝙜      1\n",
       "14137   initiated      1\n",
       "14138   initiates      1\n",
       "14139  initiation      1\n",
       "14142    injected      1\n",
       "...           ...    ...\n",
       "16451        make   2660\n",
       "29179        want   2667\n",
       "15861        like   3135\n",
       "8808          don   3613\n",
       "15023        just   4174\n",
       "\n",
       "[30296 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# putting words and counts together \n",
    "my_wordcount = pd.DataFrame(list(zip(word_list, count_list)),\n",
    "              columns=['word','count'])\n",
    "(my_wordcount.sort_values(by=['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '100',\n",
       " '15',\n",
       " '20',\n",
       " '2019',\n",
       " '30',\n",
       " '50',\n",
       " 'able',\n",
       " 'access',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'address',\n",
       " 'advice',\n",
       " 'ago',\n",
       " 'amazon',\n",
       " 'amp',\n",
       " 'app',\n",
       " 'apple',\n",
       " 'apps',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bank',\n",
       " 'basically',\n",
       " 'bed',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'body',\n",
       " 'bottle',\n",
       " 'bought',\n",
       " 'box',\n",
       " 'break',\n",
       " 'bring',\n",
       " 'business',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'called',\n",
       " 'came',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'charge',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'christmas',\n",
       " 'clean',\n",
       " 'click',\n",
       " 'close',\n",
       " 'clothes',\n",
       " 'code',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'coming',\n",
       " 'company',\n",
       " 'completely',\n",
       " 'computer',\n",
       " 'contact',\n",
       " 'cost',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'create',\n",
       " 'credit',\n",
       " 'cut',\n",
       " 'date',\n",
       " 'day',\n",
       " 'days',\n",
       " 'deal',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'different',\n",
       " 'discord',\n",
       " 'dna',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'dog',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'driving',\n",
       " 'drugs',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'email',\n",
       " 'end',\n",
       " 'equest',\n",
       " 'especially',\n",
       " 'example',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'extra',\n",
       " 'fake',\n",
       " 'family',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'food',\n",
       " 'free',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'fuck',\n",
       " 'game',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'gift',\n",
       " 'giving',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'good',\n",
       " 'google',\n",
       " 'got',\n",
       " 'great',\n",
       " 'gt',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'having',\n",
       " 'help',\n",
       " 'helps',\n",
       " 'high',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'home',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'https',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'ideas',\n",
       " 'illegal',\n",
       " 'ilpt',\n",
       " 'im',\n",
       " 'important',\n",
       " 'info',\n",
       " 'information',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'insurance',\n",
       " 'internet',\n",
       " 'iphone',\n",
       " 'isn',\n",
       " 'item',\n",
       " 'items',\n",
       " 'job',\n",
       " 'just',\n",
       " 'kids',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'later',\n",
       " 'learn',\n",
       " 'leave',\n",
       " 'left',\n",
       " 'let',\n",
       " 'life',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'link',\n",
       " 'list',\n",
       " 'little',\n",
       " 'live',\n",
       " 'll',\n",
       " 'local',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'low',\n",
       " 'lpt',\n",
       " 'mail',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'maybe',\n",
       " 'means',\n",
       " 'method',\n",
       " 'mind',\n",
       " 'minutes',\n",
       " 'money',\n",
       " 'month',\n",
       " 'months',\n",
       " 'morning',\n",
       " 'multiple',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'note',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'obviously',\n",
       " 'offer',\n",
       " 'old',\n",
       " 'ones',\n",
       " 'online',\n",
       " 'open',\n",
       " 'option',\n",
       " 'order',\n",
       " 'outside',\n",
       " 'package',\n",
       " 'paid',\n",
       " 'paper',\n",
       " 'parents',\n",
       " 'password',\n",
       " 'past',\n",
       " 'pay',\n",
       " 'paying',\n",
       " 'paypal',\n",
       " 'people',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'phone',\n",
       " 'pick',\n",
       " 'place',\n",
       " 'places',\n",
       " 'plan',\n",
       " 'play',\n",
       " 'point',\n",
       " 'police',\n",
       " 'possible',\n",
       " 'post',\n",
       " 'pretty',\n",
       " 'price',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'process',\n",
       " 'product',\n",
       " 'purchase',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quick',\n",
       " 'read',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'receipt',\n",
       " 'recently',\n",
       " 'reddit',\n",
       " 'refund',\n",
       " 'remember',\n",
       " 'remove',\n",
       " 'report',\n",
       " 'request',\n",
       " 'return',\n",
       " 'right',\n",
       " 'room',\n",
       " 'run',\n",
       " 'safe',\n",
       " 'said',\n",
       " 'save',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'scam',\n",
       " 'school',\n",
       " 'screen',\n",
       " 'search',\n",
       " 'second',\n",
       " 'security',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'sell',\n",
       " 'selling',\n",
       " 'send',\n",
       " 'sent',\n",
       " 'service',\n",
       " 'services',\n",
       " 'set',\n",
       " 'share',\n",
       " 'shit',\n",
       " 'short',\n",
       " 'sign',\n",
       " 'simple',\n",
       " 'simply',\n",
       " 'site',\n",
       " 'sites',\n",
       " 'situation',\n",
       " 'small',\n",
       " 'social',\n",
       " 'spend',\n",
       " 'start',\n",
       " 'started',\n",
       " 'state',\n",
       " 'stay',\n",
       " 'steal',\n",
       " 'step',\n",
       " 'stolen',\n",
       " 'stop',\n",
       " 'store',\n",
       " 'stores',\n",
       " 'story',\n",
       " 'stuff',\n",
       " 'sure',\n",
       " 'taking',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'tell',\n",
       " 'text',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thinking',\n",
       " 'thought',\n",
       " 'time',\n",
       " 'times',\n",
       " 'tip',\n",
       " 'tips',\n",
       " 'today',\n",
       " 'told',\n",
       " 'took',\n",
       " 'tried',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'turn',\n",
       " 'type',\n",
       " 'uk',\n",
       " 'use',\n",
       " 'used',\n",
       " 'using',\n",
       " 'usually',\n",
       " 've',\n",
       " 'video',\n",
       " 'wait',\n",
       " 'walk',\n",
       " 'walmart',\n",
       " 'wanna',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'watch',\n",
       " 'water',\n",
       " 'way',\n",
       " 'ways',\n",
       " 'website',\n",
       " 'weed',\n",
       " 'week',\n",
       " 'weeks',\n",
       " 'went',\n",
       " 'windows',\n",
       " 'won',\n",
       " 'wondering',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'working',\n",
       " 'works',\n",
       " 'worth',\n",
       " 'write',\n",
       " 'wrong',\n",
       " 'www',\n",
       " 'x200b',\n",
       " 'year',\n",
       " 'years',\n",
       " 'youtube']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking any words with count of over 200 mentions and making my stopwords list\n",
    "my_stopwords= my_wordcount.loc[my_wordcount['count'] > 200]['word'].tolist()\n",
    "(my_stopwords)\n",
    "# although not shown, Ran cvec and tvec models with my cstomer stop words and did not get any appredciable drop in scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Model 3\n",
    ">### GENERAL FINDINGS for all 3 datasets\n",
    ">- ALthough only shown in Model3/Data3, the following finding are for ALL 3 datasets.\n",
    ">- **DecisionTree accuracy is consistently lower accuracy than LogReg and had highest overift**  Although DT had at times up to 90 max depth, the model ran very quickly. \n",
    ">- **Stopwords appear not to be an issue** In addition to looking at models I also considered maybe a set of key words were influencing the accuracies of the models. Generating custom lits of stopwords did not have a significant effect on LogReg results. You had to get to the point of keeping words used 300 times in 14,000 posts (ie discarding words used over 300 times) to make any appeciable difference in the score.  This indicates individual and rarer words have more 'weight' which is probably why Tvec was consistently more accurate over Cvec overall.\n",
    "\n",
    ">### CONCLUSIONS for best fit models \n",
    "Results for best fit models:\n",
    "\n",
    "|Dataset|Reddit|Baseline|Best model|Results|\n",
    "|---|---|---|---|---|\n",
    "|Data1|Unethical vs Ethical|54%|Tvec and LogReg| Accuracy 78%|\n",
    "|Data2|Illegal vs Unethical| 52%| Tvec and LogReg|Accuracy 76%|\n",
    "|Data3|Illegal vs Ethical|52%|Tvec and LogReg|Accuracy 90%|\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
